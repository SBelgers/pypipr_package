{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2583d03c",
   "metadata": {},
   "source": [
    "# PyPIPR Package Example: Pupil Series Analysis Pipeline\n",
    "\n",
    "This example demonstrates how to analyze continuous pupillometry recordings with multiple stimuli using the PyPIPR package.\n",
    "\n",
    "## What you'll learn:\n",
    "\n",
    "1. **Series Data Loading**: How to load continuous pupillometry recordings\n",
    "2. **Data Preprocessing**: Rate limiting, smoothing, and artifact removal for series data\n",
    "3. **Series Splitting**: Extracting individual responses from continuous recordings\n",
    "4. **Batch Analysis**: Processing multiple measurements efficiently\n",
    "5. **Comparative Analysis**: Analyzing response consistency across trials\n",
    "6. **Visualization**: Creating comprehensive series plots\n",
    "\n",
    "## Package Structure Used:\n",
    "\n",
    "- `pypipr.data` - Example dataset loading\n",
    "- `pypipr.core` - Core data structures (PupilSeries, PupilMeasurement)\n",
    "- `pypipr.analysis.fitting` - Comprehensive fitting with PupilFit\n",
    "- `pypipr.preprocessing` - Data cleaning and filtering\n",
    "\n",
    "Perfect for analyzing experimental sessions with multiple trials! ðŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184856e9",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Libraries\n",
    "\n",
    "Import all necessary libraries and modules from the reorganized PyPIPR package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypipr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import specific functions from reorganized modules\n",
    "from pypipr.data import load_real_series\n",
    "from pypipr.analysis.fitting import PupilFit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6f5f3",
   "metadata": {},
   "source": [
    "# Step 2: Load and Explore Series Data\n",
    "\n",
    "We'll work with real pupillometry data that contains multiple light stimuli in a continuous recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real pupillometry series data with multiple stimuli\n",
    "print(\"Loading real pupil series data...\")\n",
    "series = load_real_series()\n",
    "\n",
    "print(f\"Series data: {len(series.get_time())} time points\")\n",
    "print(f\"Time range: {series.get_time()[0]:.1f}s to {series.get_time()[-1]:.1f}s\")\n",
    "print(f\"Number of light stimuli: {len(series.get_light_stimuli().get_times())}\")\n",
    "\n",
    "# Show stimulus timing\n",
    "stimuli_times = series.get_light_stimuli().get_times()\n",
    "for i, (start, end) in enumerate(stimuli_times):\n",
    "    print(f\"Stimulus {i+1}: {start:.1f}s - {end:.1f}s (duration: {end-start:.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc568fd",
   "metadata": {},
   "source": [
    "# Step 3: Visualize Raw Series Data\n",
    "\n",
    "Let's first look at the complete series to understand the data structure and identify any obvious artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the complete series with stimulus markers\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 6))\n",
    "\n",
    "# Plot pupil trace\n",
    "series.plot(ax=ax, label=\"Pupil Trace\", color=\"darkblue\", alpha=0.8, linewidth=1)\n",
    "\n",
    "# Add light stimuli markers\n",
    "series.plot_light_stimulus(ax=ax, color=\"yellow\", alpha=0.4, label=\"Light Stimuli\")\n",
    "\n",
    "ax.set_title(\"Complete Pupillometry Series with Multiple Light Stimuli\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Pupil Size (mm)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show basic statistics\n",
    "pupil_data = series.get_size()\n",
    "print(f\"\\nSeries Statistics:\")\n",
    "print(f\"Mean pupil size: {np.mean(pupil_data):.3f} mm\")\n",
    "print(f\"Standard deviation: {np.std(pupil_data):.3f} mm\")\n",
    "print(f\"Range: {np.min(pupil_data):.3f} - {np.max(pupil_data):.3f} mm\")\n",
    "print(f\"Recording duration: {series.get_time()[-1] - series.get_time()[0]:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31630419",
   "metadata": {},
   "source": [
    "# Step 4: Series Data Preprocessing Pipeline\n",
    "\n",
    "Real pupillometry data often contains artifacts and noise. Let's apply a comprehensive preprocessing pipeline to clean the continuous series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9af415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate preprocessing pipeline for series data\n",
    "fig, ax = plt.subplots(4, 1, figsize=(16, 14), sharex=True)\n",
    "\n",
    "# Step 1: Original data\n",
    "series.plot(ax=ax[0], label=\"Raw Pupil Trace\", color=\"darkblue\", alpha=0.7)\n",
    "ax[0].set_title(\"Step 1: Raw Series Data\")\n",
    "ax[0].set_ylabel(\"Pupil Size (mm)\")\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Step 2: Rate limiting (remove artifacts)\n",
    "series_step2 = series.copy()\n",
    "series_step2.limit_rate_of_change(2.0)  # Remove points with >2 mm/s change\n",
    "series_step2.drop_nan()\n",
    "series_step2.plot(ax=ax[1], label=\"Rate Limited (< 2 mm/s)\", color=\"orange\", alpha=0.8)\n",
    "ax[1].set_title(\"Step 2: Rate Limiting (Artifact Removal)\")\n",
    "ax[1].set_ylabel(\"Pupil Size (mm)\")\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Step 3: Smoothing\n",
    "series_step3 = series_step2.copy()\n",
    "series_step3.rolling_mean(0.5)  # 0.5 second rolling mean\n",
    "series_step3.plot(ax=ax[2], label=\"Smoothed (0.5s window)\", color=\"purple\", alpha=0.8)\n",
    "ax[2].set_title(\"Step 3: Smoothing Filter\")\n",
    "ax[2].set_ylabel(\"Pupil Size (mm)\")\n",
    "ax[2].legend()\n",
    "ax[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Step 4: Final with light stimuli\n",
    "series_final = series_step3\n",
    "series_final.plot(ax=ax[3], label=\"Processed Data\", color=\"darkgreen\", linewidth=2)\n",
    "series_final.plot_light_stimulus(ax=ax[3], color=\"yellow\", alpha=0.4, label=\"Light Stimuli\")\n",
    "ax[3].set_title(\"Step 4: Final Processed Series with Light Stimuli\")\n",
    "ax[3].set_xlabel(\"Time (s)\")\n",
    "ax[3].set_ylabel(\"Pupil Size (mm)\")\n",
    "ax[3].legend()\n",
    "ax[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Data quality improvement:\")\n",
    "print(f\"Data points removed by rate limiting: {len(series.get_time()) - len(series_step2.get_time())}\")\n",
    "print(f\"Percentage of data retained: {100 * len(series_step2.get_time()) / len(series.get_time()):.1f}%\")\n",
    "print(f\"Noise reduction (std): {np.std(series.get_size()):.3f} â†’ {np.std(series_final.get_size()):.3f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a6727",
   "metadata": {},
   "source": [
    "# Step 5: Split Series into Individual Measurements\n",
    "\n",
    "Now we'll extract individual pupil responses from the continuous series data around each light stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056194d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the series into individual measurements around each stimulus\n",
    "print(\"Splitting series into individual measurements...\")\n",
    "pupil_measurements = series_final.split(prepulse_duration=10.0, postpulse_duration=30.0)\n",
    "print(f\"Created {len(pupil_measurements)} individual measurements\")\n",
    "\n",
    "# Show details about each extracted measurement\n",
    "for i, measurement in enumerate(pupil_measurements):\n",
    "    time_range = measurement.get_time()[-1] - measurement.get_time()[0]\n",
    "    stimulus_info = measurement.get_light_stimulus()\n",
    "    baseline = measurement.find_baseline(duration=5.0)\n",
    "    \n",
    "    print(f\"\\nMeasurement {i+1}:\")\n",
    "    print(f\"  Time range: {time_range:.1f} seconds\")\n",
    "    print(f\"  Data points: {len(measurement.get_time())}\")\n",
    "    print(f\"  Baseline: {baseline:.3f} mm\")\n",
    "    print(f\"  Light stimulus: {stimulus_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765a723",
   "metadata": {},
   "source": [
    "# Step 6: Visualize Individual Measurements\n",
    "\n",
    "Let's plot each extracted measurement to see the individual pupil responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50faa0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each individual measurement\n",
    "fig, axes = plt.subplots(len(pupil_measurements), 1, figsize=(15, 4*len(pupil_measurements)), \n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "if len(pupil_measurements) == 1:\n",
    "    axes = [axes]  # Make it iterable for single subplot\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange']  # Different colors for each measurement\n",
    "\n",
    "for i, measurement in enumerate(pupil_measurements):\n",
    "    ax = axes[i]\n",
    "    color = colors[i % len(colors)]\n",
    "    \n",
    "    # Apply baseline correction for better visualization\n",
    "    measurement_corrected = measurement.copy()\n",
    "    baseline = measurement_corrected.find_baseline(duration=5.0)\n",
    "    measurement_corrected.apply_baseline(baseline)\n",
    "    \n",
    "    # Plot measurement\n",
    "    measurement_corrected.plot(ax=ax, label=f\"Measurement {i+1} (Baseline Corrected)\", \n",
    "                              color=color, alpha=0.8, linewidth=2)\n",
    "    \n",
    "    # Plot light stimulus\n",
    "    measurement.plot_light_stimulus(ax=ax, alpha=0.4, color=\"yellow\", label=\"Light Stimulus\")\n",
    "    \n",
    "    # Add baseline reference line\n",
    "    ax.axhline(y=1.0, color='gray', linestyle='--', alpha=0.5, label='Baseline')\n",
    "    \n",
    "    ax.set_title(f\"Individual Measurement {i+1} - Pupil Light Response\")\n",
    "    ax.set_ylabel(\"Relative Pupil Size\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some basic metrics as text\n",
    "    pupil_data = measurement_corrected.get_size()\n",
    "    min_response = np.min(pupil_data)\n",
    "    max_constriction = 1.0 - min_response\n",
    "    \n",
    "    ax.text(0.02, 0.98, f'Max Constriction: {max_constriction:.2f}\\nBaseline: {baseline:.2f} mm', \n",
    "            transform=ax.transAxes, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "axes[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac8c80",
   "metadata": {},
   "source": [
    "# Step 7: Comprehensive Batch Analysis\n",
    "\n",
    "Now we'll perform comprehensive fitting analysis on all individual measurements and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive fits for each measurement\n",
    "print(\"Performing comprehensive fitting analysis on all measurements...\")\n",
    "fits = []\n",
    "fit_params = []\n",
    "\n",
    "for i, measurement in enumerate(pupil_measurements):\n",
    "    print(f\"Fitting measurement {i+1}...\")\n",
    "    \n",
    "    # Apply baseline correction\n",
    "    measurement_corrected = measurement.copy()\n",
    "    baseline = measurement_corrected.find_baseline(duration=5.0)\n",
    "    measurement_corrected.apply_baseline(baseline)\n",
    "    \n",
    "    # Create and fit comprehensive model\n",
    "    fit = PupilFit.from_measurement(measurement_corrected)\n",
    "    fit.fit_all()\n",
    "    \n",
    "    fits.append(fit)\n",
    "    \n",
    "    # Extract parameters\n",
    "    params = fit.get_all_params()\n",
    "    fit_params.append(params)\n",
    "    \n",
    "    print(f\"  Fit completed for measurement {i+1}\")\n",
    "\n",
    "print(f\"\\nCompleted fitting for {len(fits)} measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f42d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fits for all measurements\n",
    "fig, axes = plt.subplots(len(pupil_measurements), 1, figsize=(15, 4*len(pupil_measurements)), \n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "if len(pupil_measurements) == 1:\n",
    "    axes = [axes]  # Make it iterable for single subplot\n",
    "\n",
    "for i, (measurement, fit) in enumerate(zip(pupil_measurements, fits)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Apply baseline correction\n",
    "    measurement_corrected = measurement.copy()\n",
    "    baseline = measurement_corrected.find_baseline(duration=5.0)\n",
    "    measurement_corrected.apply_baseline(baseline)\n",
    "    \n",
    "    # Plot raw measurement\n",
    "    measurement_corrected.plot(ax=ax, label=f\"Measurement {i+1}\", color=\"blue\", alpha=0.7)\n",
    "    \n",
    "    # Plot light stimulus\n",
    "    measurement.plot_light_stimulus(ax=ax, alpha=0.4, color=\"yellow\", label=\"Light Stimulus\")\n",
    "    \n",
    "    # Plot comprehensive fit\n",
    "    time_fit = np.linspace(measurement_corrected.get_time()[0], measurement_corrected.get_time()[-1], 500)\n",
    "    prediction = fit.predict(time_fit)\n",
    "    ax.plot(time_fit, prediction, 'r--', linewidth=2, alpha=0.8, label=\"Complete Fit\")\n",
    "    \n",
    "    ax.set_title(f\"Measurement {i+1} - Data and Comprehensive Fit\")\n",
    "    ax.set_ylabel(\"Relative Pupil Size\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add parameter info\n",
    "    params = fit_params[i]\n",
    "    param_text = \"\\n\".join([f\"{k}: {v}\" for k, v in list(params.items())[:3]])  # Show first 3 params\n",
    "    ax.text(0.98, 0.98, param_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "axes[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76875a8a",
   "metadata": {},
   "source": [
    "# Step 8: Cross-Trial Analysis and Comparison\n",
    "\n",
    "Let's analyze the consistency and variability across all measurements in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key metrics from all measurements for comparison\n",
    "print(\"=== CROSS-TRIAL ANALYSIS ===\\n\")\n",
    "\n",
    "# Collect metrics from all measurements\n",
    "baselines = []\n",
    "max_constrictions = []\n",
    "response_latencies = []\n",
    "\n",
    "for i, measurement in enumerate(pupil_measurements):\n",
    "    # Apply baseline correction\n",
    "    measurement_corrected = measurement.copy()\n",
    "    baseline = measurement_corrected.find_baseline(duration=5.0)\n",
    "    measurement_corrected.apply_baseline(baseline)\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    pupil_data = measurement_corrected.get_size()\n",
    "    time_data = measurement_corrected.get_time()\n",
    "    \n",
    "    baselines.append(baseline)\n",
    "    \n",
    "    # Max constriction (1.0 - minimum relative size)\n",
    "    min_response = np.min(pupil_data)\n",
    "    max_constriction = 1.0 - min_response\n",
    "    max_constrictions.append(max_constriction)\n",
    "    \n",
    "    # Response latency (time to reach 10% of max constriction)\n",
    "    constriction_threshold = 1.0 - 0.1 * max_constriction\n",
    "    latency_indices = np.where((pupil_data < constriction_threshold) & (time_data > 0))[0]\n",
    "    latency = time_data[latency_indices[0]] - time_data[0] if len(latency_indices) > 0 else np.nan\n",
    "    response_latencies.append(latency)\n",
    "    \n",
    "    print(f\"Measurement {i+1}:\")\n",
    "    print(f\"  Baseline: {baseline:.3f} mm\")\n",
    "    print(f\"  Max Constriction: {max_constriction:.3f} (relative)\")\n",
    "    print(f\"  Response Latency: {latency:.3f} s\")\n",
    "    print()\n",
    "\n",
    "# Calculate summary statistics\n",
    "print(\"SUMMARY STATISTICS ACROSS ALL TRIALS:\")\n",
    "print(f\"Baseline diameter: {np.mean(baselines):.3f} Â± {np.std(baselines):.3f} mm\")\n",
    "print(f\"Max constriction: {np.mean(max_constrictions):.3f} Â± {np.std(max_constrictions):.3f}\")\n",
    "print(f\"Response latency: {np.nanmean(response_latencies):.3f} Â± {np.nanstd(response_latencies):.3f} s\")\n",
    "\n",
    "# Calculate coefficient of variation (CV) for reliability assessment\n",
    "cv_baseline = np.std(baselines) / np.mean(baselines) * 100\n",
    "cv_constriction = np.std(max_constrictions) / np.mean(max_constrictions) * 100\n",
    "cv_latency = np.nanstd(response_latencies) / np.nanmean(response_latencies) * 100\n",
    "\n",
    "print(f\"\\nCOEFFICIENT OF VARIATION (reliability):\")\n",
    "print(f\"Baseline CV: {cv_baseline:.1f}%\")\n",
    "print(f\"Max constriction CV: {cv_constriction:.1f}%\")\n",
    "print(f\"Response latency CV: {cv_latency:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: All measurements overlaid (baseline corrected)\n",
    "ax1 = axes[0, 0]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(pupil_measurements)))\n",
    "\n",
    "for i, measurement in enumerate(pupil_measurements):\n",
    "    measurement_corrected = measurement.copy()\n",
    "    baseline = measurement_corrected.find_baseline(duration=5.0)\n",
    "    measurement_corrected.apply_baseline(baseline)\n",
    "    \n",
    "    # Normalize time to start from stimulus onset\n",
    "    time_normalized = measurement_corrected.get_time() - measurement_corrected.get_time()[0]\n",
    "    ax1.plot(time_normalized, measurement_corrected.get_size(), \n",
    "            color=colors[i], alpha=0.7, label=f'Trial {i+1}')\n",
    "\n",
    "# Add average response\n",
    "if len(pupil_measurements) > 1:\n",
    "    # Calculate average (simplified - assumes same time points)\n",
    "    ax1.axhline(y=1.0, color='black', linestyle='--', alpha=0.5, label='Baseline')\n",
    "\n",
    "ax1.set_title('All Trials Overlaid (Baseline Corrected)')\n",
    "ax1.set_xlabel('Time from Trial Start (s)')\n",
    "ax1.set_ylabel('Relative Pupil Size')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Metric comparison across trials\n",
    "ax2 = axes[0, 1]\n",
    "trial_numbers = range(1, len(pupil_measurements) + 1)\n",
    "\n",
    "ax2_twin = ax2.twinx()\n",
    "line1 = ax2.plot(trial_numbers, baselines, 'o-', color='blue', label='Baseline (mm)', markersize=8)\n",
    "line2 = ax2_twin.plot(trial_numbers, max_constrictions, 's-', color='red', label='Max Constriction', markersize=8)\n",
    "\n",
    "ax2.set_xlabel('Trial Number')\n",
    "ax2.set_ylabel('Baseline Diameter (mm)', color='blue')\n",
    "ax2_twin.set_ylabel('Max Constriction (relative)', color='red')\n",
    "ax2.set_title('Metrics Across Trials')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Combine legends\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax2.legend(lines, labels, loc='upper right')\n",
    "\n",
    "# Plot 3: Response latency across trials\n",
    "ax3 = axes[1, 0]\n",
    "valid_latencies = [lat for lat in response_latencies if not np.isnan(lat)]\n",
    "valid_trials = [i+1 for i, lat in enumerate(response_latencies) if not np.isnan(lat)]\n",
    "\n",
    "ax3.plot(valid_trials, valid_latencies, 'o-', color='green', markersize=8, linewidth=2)\n",
    "ax3.axhline(y=np.nanmean(response_latencies), color='green', linestyle='--', alpha=0.7, \n",
    "           label=f'Mean: {np.nanmean(response_latencies):.2f}s')\n",
    "ax3.set_xlabel('Trial Number')\n",
    "ax3.set_ylabel('Response Latency (s)')\n",
    "ax3.set_title('Response Latency Across Trials')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Summary statistics\n",
    "ax4 = axes[1, 1]\n",
    "metrics = ['Baseline\\n(mm)', 'Max Constr.\\n(rel.)', 'Latency\\n(s)']\n",
    "means = [np.mean(baselines), np.mean(max_constrictions), np.nanmean(response_latencies)]\n",
    "stds = [np.std(baselines), np.std(max_constrictions), np.nanstd(response_latencies)]\n",
    "\n",
    "bars = ax4.bar(metrics, means, yerr=stds, capsize=5, alpha=0.7, color=['blue', 'red', 'green'])\n",
    "ax4.set_title('Mean Â± SD Across All Trials')\n",
    "ax4.set_ylabel('Value')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + std + 0.01,\n",
    "             f'{mean:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e970b35",
   "metadata": {},
   "source": [
    "# Step 9: Summary and Conclusions\n",
    "\n",
    "Let's summarize what we've learned about pupillometry series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239741f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PUPILLOMETRY SERIES ANALYSIS SUMMARY ===\\n\")\n",
    "\n",
    "print(\"1. SERIES DATA CHARACTERISTICS:\")\n",
    "print(f\"   âœ“ Total recording duration: {series.get_time()[-1] - series.get_time()[0]:.1f} seconds\")\n",
    "print(f\"   âœ“ Number of stimuli: {len(pupil_measurements)}\")\n",
    "print(f\"   âœ“ Data points before preprocessing: {len(series.get_time())}\")\n",
    "print(f\"   âœ“ Data points after preprocessing: {len(series_final.get_time())}\")\n",
    "print(f\"   âœ“ Data retention rate: {100 * len(series_final.get_time()) / len(series.get_time()):.1f}%\")\n",
    "\n",
    "print(f\"\\n2. PREPROCESSING PIPELINE EFFECTIVENESS:\")\n",
    "print(f\"   âœ“ Artifact removal: Rate limiting < 2 mm/s\")\n",
    "print(f\"   âœ“ Noise reduction: {np.std(series.get_size()):.3f} â†’ {np.std(series_final.get_size()):.3f} mm\")\n",
    "print(f\"   âœ“ Smoothing: 0.5s rolling window applied\")\n",
    "print(f\"   âœ“ Signal preservation: Key features maintained\")\n",
    "\n",
    "print(f\"\\n3. INDIVIDUAL MEASUREMENT EXTRACTION:\")\n",
    "print(f\"   âœ“ Successfully extracted {len(pupil_measurements)} individual responses\")\n",
    "print(f\"   âœ“ Pre-pulse duration: 10.0 seconds\")\n",
    "print(f\"   âœ“ Post-pulse duration: 30.0 seconds\")\n",
    "print(f\"   âœ“ All measurements include baseline and recovery periods\")\n",
    "\n",
    "print(f\"\\n4. CROSS-TRIAL CONSISTENCY:\")\n",
    "print(f\"   â€¢ Baseline reliability (CV): {cv_baseline:.1f}%\")\n",
    "print(f\"   â€¢ Max constriction reliability (CV): {cv_constriction:.1f}%\")\n",
    "print(f\"   â€¢ Response latency reliability (CV): {cv_latency:.1f}%\")\n",
    "\n",
    "reliability_assessment = \"Excellent\" if cv_constriction < 10 else \"Good\" if cv_constriction < 20 else \"Fair\"\n",
    "print(f\"   âœ“ Overall reliability: {reliability_assessment}\")\n",
    "\n",
    "print(f\"\\n5. COMPREHENSIVE FITTING RESULTS:\")\n",
    "print(f\"   âœ“ Successfully fitted {len(fits)} individual measurements\")\n",
    "print(f\"   âœ“ All phases analyzed: baseline, constriction, sustained, redilation\")\n",
    "print(f\"   âœ“ Model predictions generated for each trial\")\n",
    "print(f\"   âœ“ Parameter extraction completed\")\n",
    "\n",
    "print(f\"\\n6. PACKAGE CAPABILITIES DEMONSTRATED:\")\n",
    "print(\"   âœ“ Continuous series data loading and preprocessing\")\n",
    "print(\"   âœ“ Multi-stimulus series analysis\")\n",
    "print(\"   âœ“ Automated measurement extraction\")\n",
    "print(\"   âœ“ Batch processing and fitting\")\n",
    "print(\"   âœ“ Cross-trial consistency analysis\")\n",
    "print(\"   âœ“ Comprehensive visualization suite\")\n",
    "print(\"   âœ“ Statistical reliability assessment\")\n",
    "\n",
    "print(f\"\\n=== SERIES ANALYSIS COMPLETE! ===\\n\")\n",
    "print(f\"This example demonstrated the complete pipeline for analyzing pupillometry series data.\")\n",
    "print(f\"Perfect for experimental sessions with multiple trials and longitudinal studies! ðŸš€\")\n",
    "\n",
    "print(f\"\\nNext steps you might consider:\")\n",
    "print(f\"â€¢ Export results to CSV/Excel for further statistical analysis\")\n",
    "print(f\"â€¢ Compare series across different experimental conditions\")\n",
    "print(f\"â€¢ Analyze habituation or adaptation effects across trials\")\n",
    "print(f\"â€¢ Investigate individual differences in response patterns\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
